{
  "hadoop": {
    "core-site.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/core-default.html
      // note: any value (int, float, boolean, string) must be enclosed in double quotes and here is a sample:
      // "io.file.buffer.size": "4096"
    },
    "hdfs-site.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/hdfs-default.html
    },
    "mapred-site.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/mapred-default.html
    },
    "hadoop-env.sh": {
      // "HADOOP_HEAPSIZE": "",
      // "HADOOP_NAMENODE_OPTS": "",
      // "HADOOP_DATANODE_OPTS": "",
      // "HADOOP_SECONDARYNAMENODE_OPTS": "",
      // "HADOOP_JOBTRACKER_OPTS": "",
      // "HADOOP_TASKTRACKER_OPTS": "",
      // "HADOOP_CLASSPATH": "",
      // "JAVA_HOME": "",
      // "PATH": ""
    },
    "log4j.properties": {
      // "hadoop.root.logger": "INFO,RFA",
      // "log4j.appender.RFA.MaxBackupIndex": "10",
      // "log4j.appender.RFA.MaxFileSize": "100MB",
      // "hadoop.security.logger": "DEBUG,DRFA"
    },
    "hadoop-metrics.properties": {
      // check for all settings at http://wiki.apache.org/hadoop/GangliaMetrics
    },
    "hadoop-metrics2.properties": {
      // all items in hadoop-metrics2.properties can be configured
    },
    "topology.data": {
      // topology.data will be generated by Serengeti if you specify network topology when creating the cluster.
      // if needed, you can override the generated topology data or add more.
      // "text": "ip1 /rack1,ip2 /rack2,..."
    },
    "fair-scheduler.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/fair_scheduler.html
      // "text": "the full content of fair-scheduler.xml in one line"
    },
    "capacity-scheduler.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/capacity_scheduler.html
    },
    "mapred-queue-acls.xml": {
      // check for all settings at http://hadoop.apache.org/docs/stable/cluster_setup.html#Configuring+the+Hadoop+Daemons
      // "mapred.queue.queue-name.acl-submit-job": "",
      // "mapred.queue.queue-name.acl-administer-jobs": ""
    }
  },
  "hbase": {
    "hbase-site.xml": {
      // check for all settings at http://hbase.apache.org/configuration.html#hbase.site
    },
    "hbase-env.sh": {
      // "JAVA_HOME": "",
      // "PATH": "",
      // "HBASE_CLASSPATH": "",
      // "HBASE_HEAPSIZE": "",
      // "HBASE_OPTS": "",
      // "HBASE_USE_GC_LOGFILE": "",
      // "HBASE_JMX_BASE": "",
      // "HBASE_MASTER_OPTS": "",
      // "HBASE_REGIONSERVER_OPTS": "",
      // "HBASE_THRIFT_OPTS": "",
      // "HBASE_ZOOKEEPER_OPTS": "",
      // "HBASE_REGIONSERVERS": "",
      // "HBASE_SSH_OPTS": "",
      // "HBASE_NICENESS": "",
      // "HBASE_SLAVE_SLEEP": ""
    },
    "log4j.properties": {
      // "hbase.root.logger": "DEBUG,DRFA"
    }
  },
  "zookeeper": {
    "java.env": {
      // "JVMFLAGS": "-Xmx2g"
    },
    "log4j.properties": {
      // "zookeeper.root.logger": "DEBUG,DRFA"
    }
  }
}
